{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "482b56fd-849f-4142-bdf7-2355d7427b01",
   "metadata": {
    "id": "482b56fd-849f-4142-bdf7-2355d7427b01"
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44327d2a-b0da-4a80-8c25-5ea272d83c2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44327d2a-b0da-4a80-8c25-5ea272d83c2f",
    "outputId": "c9650370-cfd4-4e62-80e1-37fcff3e4a29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В наборе предложений: \n",
      " 14412\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./labeled_rutoxic.csv\", delimiter=',', header=0, names=['sentence', 'label'])\n",
    "\n",
    "print('В наборе предложений: \\n',df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5f651c3-a790-40d9-901f-3d49c5d672aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5f651c3-a790-40d9-901f-3d49c5d672aa",
    "outputId": "062d1ec8-9b32-4ad7-e585-1cf607ee221c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic: 4826\n",
      "not toxic: 9586\n"
     ]
    }
   ],
   "source": [
    "print('toxic:', df[df['label'] > 0]['label'].count())\n",
    "print('not toxic:', df[df['label'] < 1]['label'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cd8300-5eeb-4bb3-bbe1-d5264483c74b",
   "metadata": {
    "id": "a2cd8300-5eeb-4bb3-bbe1-d5264483c74b"
   },
   "source": [
    "## Разбиение на тестовые и обучающие"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fffe44dd-9d8c-4393-84c4-234e2b6acdd0",
   "metadata": {
    "id": "fffe44dd-9d8c-4393-84c4-234e2b6acdd0"
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:,0]#\n",
    "y = df.iloc[:,1]#\n",
    "\n",
    "train , test , y_train, y_test = train_test_split(X, y, test_size=0.3) # и отдаем 30% на тест, остальное на обучен"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1eb41e-b113-4013-9cdc-cb71afaa3af7",
   "metadata": {
    "id": "2b1eb41e-b113-4013-9cdc-cb71afaa3af7"
   },
   "source": [
    "## Разбиение на слова с помощью модели Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c41623a-ee01-455e-818b-753fd394c2ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c41623a-ee01-455e-818b-753fd394c2ce",
    "outputId": "6b3afc4d-1d7f-4e85-c7b7-a4bd3e28b6ab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\IVAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\IVAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentences_train:\n",
      "1590     [сдается, мне, в, этой, конторе, нанимают, тех...\n",
      "243      [я, дурачок, купил, игра, гавно, однообразно, ...\n",
      "12632    [ну, спасибо, столько, раз, на, это, и, вживую...\n",
      "239      [ты, троллишь, если, ты, такой, правильный, пл...\n",
      "10500    [мой, личный, топ, 3, трилогия, ме, дилогия, к...\n",
      "4184     [ну, например, там, было, написано, что, я, не...\n",
      "7928     [сомневаюсь, что, их, когда, нибудь, все, откр...\n",
      "2549            [интересно, почему, сейчас, не, обсуждают]\n",
      "13705    [дрожин, кусок, говна, с, мерзким, ебалом, ско...\n",
      "12803    [вот, расположение, только, я, не, местный, та...\n",
      "Name: sentence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Инициализация лемматизатора\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Метод преобразования текста в слова\n",
    "def text_to_words(raw_text, remove_stopwords=False):\n",
    "    # Удаление лишних символов, оставляем только буквы и цифры\n",
    "    letters_and_numbers_only = re.sub(\"[^0-9а-яА-Я]\", \" \", raw_text)\n",
    "\n",
    "    # Приведение к нижнему регистру и токенизация\n",
    "    words = letters_and_numbers_only.lower().split()\n",
    "\n",
    "    # Удаление стоп-слов, если требуется\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"russian\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "\n",
    "    # Лемматизация\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    return words\n",
    "\n",
    "sentences_train = train.apply(text_to_words, remove_stopwords=False)\n",
    "sentences_test = test.apply(text_to_words, remove_stopwords=False)\n",
    "print(\"\\nSentences_train:\")\n",
    "print(sentences_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00c38fd3-7566-4a1c-abac-1d05e50279c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00c38fd3-7566-4a1c-abac-1d05e50279c2",
    "outputId": "003c8cc6-93f1-4d72-a109-83b9bd2f444d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1590    [сдается, мне, в, этой, конторе, нанимают, тех...\n",
      "Name: sentence, dtype: object\n",
      "(300,)\n",
      "[-9.73262712e-02  6.57440200e-02 -1.32309929e-01  3.99766788e-02\n",
      "  1.35120109e-01 -2.58908629e-01 -1.65641308e-03  2.61599869e-01\n",
      "  1.77603990e-01 -1.92030847e-01  4.38472509e-01  8.04604366e-02\n",
      " -4.32155095e-02 -1.59699544e-01 -4.70517464e-02 -1.63453922e-01\n",
      "  2.01564759e-01  8.51944238e-02  2.57914841e-01  2.31918290e-01\n",
      " -1.55077921e-02  5.73461577e-02  3.31430107e-01  3.72655660e-01\n",
      "  2.81931937e-01  2.12377906e-01 -2.33935580e-01 -5.03270030e-02\n",
      "  4.14911881e-02 -3.09999198e-01 -2.17044838e-02 -3.03304672e-01\n",
      " -7.79279135e-03 -6.05441444e-02 -5.33397794e-02  2.67152160e-01\n",
      " -2.60980725e-01 -2.34153882e-01 -3.16376239e-01 -2.37054005e-02\n",
      " -1.06440969e-01  3.14049184e-01  9.73007828e-02  5.15800789e-02\n",
      "  1.69119850e-01 -6.27417937e-02  5.10144942e-02  1.41896471e-01\n",
      "  5.86675946e-03 -4.02600057e-02  5.54032959e-02  4.99141105e-02\n",
      " -3.14812958e-02 -2.85249591e-01 -3.01640313e-02  2.03316081e-02\n",
      "  2.02306375e-01 -1.27514660e-01 -1.43764734e-01 -6.83689117e-02\n",
      "  2.05542948e-02 -2.27197204e-02  2.16250136e-01 -2.45412197e-02\n",
      " -4.12680842e-02  1.53132845e-02 -1.52424231e-01  2.35129856e-02\n",
      " -5.08932360e-02 -2.25963533e-01 -7.59071037e-02 -9.72073525e-02\n",
      "  1.50399774e-01  1.16991185e-01 -1.20388389e-01  4.38038781e-02\n",
      " -3.18425260e-02 -8.76852348e-02 -3.47901583e-01  2.28079762e-02\n",
      " -3.11092157e-02  1.34068370e-01 -1.03400804e-01  1.56207040e-01\n",
      "  2.42054579e-03 -1.44489586e-01 -3.02556664e-01  1.84196442e-01\n",
      "  1.51397079e-01 -5.70739470e-02  6.44840971e-02 -3.57436202e-02\n",
      "  7.41496384e-02 -8.39667022e-02  1.84712052e-01  1.95693493e-01\n",
      " -2.41980985e-01  8.09776876e-03 -4.00547683e-02 -1.07660420e-01\n",
      " -7.47094229e-02 -1.44846246e-01  6.27141297e-02 -1.51510805e-01\n",
      "  1.42934799e-01  2.80023336e-01  1.09008513e-01 -3.84145649e-03\n",
      " -1.67342797e-01  1.13257334e-01  1.69771433e-01 -2.63209511e-02\n",
      " -1.31273344e-01  1.97058514e-01  4.62879107e-04  5.00840694e-02\n",
      " -1.91618651e-02  1.23541944e-01  2.89040301e-02  3.03409491e-02\n",
      "  1.21629074e-01  1.38735414e-01  1.02842040e-01  4.23944090e-03\n",
      " -1.61138207e-01 -8.17747936e-02  6.83477148e-02  8.80659968e-02\n",
      " -2.48970270e-01  8.75342041e-02  3.35590810e-01  1.19708568e-01\n",
      "  2.04680502e-01  3.40420268e-02  9.42908153e-02  2.53147520e-02\n",
      "  1.35923296e-01 -2.19028264e-01 -2.67814845e-01  1.02656908e-01\n",
      " -1.01069640e-02 -1.99017361e-01 -1.49007753e-01  2.08803684e-01\n",
      "  1.51468396e-01 -2.93030888e-01 -7.08030537e-03 -2.34649748e-01\n",
      "  3.81421775e-01 -9.78847295e-02  2.76640691e-02 -2.83882052e-01\n",
      "  1.98174585e-02  2.40535177e-02 -1.42641857e-01 -5.08882925e-02\n",
      " -6.30586371e-02 -2.01561749e-01 -8.65106122e-05  6.16362840e-02\n",
      "  4.45605293e-02 -3.38854231e-02 -2.37597167e-01  1.96812361e-01\n",
      " -2.34644011e-01  6.92414865e-02  2.33096436e-01  8.12580511e-02\n",
      "  8.16165730e-02  1.21253967e-01 -2.88352724e-02  1.09873667e-01\n",
      "  2.28411019e-01  2.33356938e-01 -5.37922755e-02  2.21064776e-01\n",
      "  7.17282444e-02  1.71115741e-01  9.56500992e-02 -2.58950025e-01\n",
      " -3.66870388e-02 -3.71739478e-03 -1.44078642e-01 -7.30352998e-02\n",
      "  2.24553704e-01  1.74316958e-01  4.22513299e-02 -5.49104484e-03\n",
      "  2.10461274e-01 -1.53218672e-01 -2.34907195e-01 -1.19442098e-01\n",
      "  5.19645587e-02 -8.98270961e-03  2.35556275e-01 -8.34702253e-02\n",
      "  1.62849352e-01  1.47747132e-03  1.25773355e-01  3.96875031e-02\n",
      " -3.17301065e-01 -1.35332987e-01 -2.79052202e-02  1.38838083e-01\n",
      "  5.44162318e-02 -2.47652419e-02 -1.89563274e-01 -2.32921690e-01\n",
      " -1.62277922e-01 -8.26828182e-02 -2.02731062e-02 -2.51541764e-01\n",
      " -2.12718502e-01  3.54675986e-02 -9.30617079e-02 -1.99162498e-01\n",
      " -2.92770088e-01 -2.90263712e-01 -2.28658333e-01 -2.91388571e-01\n",
      "  2.08023727e-01  2.52941012e-01 -9.03364271e-02  5.45545444e-02\n",
      " -5.00104576e-03 -2.58800238e-01  1.47337288e-01 -2.03261003e-01\n",
      " -1.38834342e-01 -1.19165303e-02  1.93469077e-02 -7.85696134e-02\n",
      " -1.95495829e-01  1.87948428e-03  4.42611948e-02  1.32904639e-02\n",
      " -1.28365397e-01 -1.25467908e-02 -1.33453012e-01 -1.50525406e-01\n",
      "  6.71904609e-02  1.98590219e-01 -1.41107693e-01 -1.46507755e-01\n",
      " -1.07644901e-01 -3.30283552e-01  1.16087690e-01  1.29734218e-01\n",
      " -4.61813956e-02  3.54795486e-01  6.39792010e-02 -1.77687649e-02\n",
      "  1.93156719e-01  7.81169236e-02 -3.75111550e-01  1.79865822e-01\n",
      "  3.17913182e-02 -1.40714765e-01 -1.59953326e-01 -1.67113751e-01\n",
      "  2.30183735e-01  4.20995235e-01  4.00653630e-01 -4.87039626e-01\n",
      " -3.85664731e-01 -7.57695874e-03  4.84323837e-02  1.76081449e-01\n",
      " -2.74308711e-01 -1.42894551e-01 -5.38124926e-02  2.83926308e-01\n",
      "  2.85136431e-01 -1.30104452e-01  4.49940532e-01  1.85012400e-01\n",
      " -1.81636587e-02  8.98298770e-02 -3.65743488e-01 -2.47345388e-01\n",
      "  2.67453015e-01 -2.59752959e-01 -1.51355982e-01 -8.79602060e-02\n",
      " -1.43346310e-01 -5.40576577e-02 -7.34727859e-01  3.97477478e-01\n",
      "  3.31005827e-02  2.95472264e-01 -8.71345550e-02  5.58054328e-01\n",
      "  7.40279928e-02  3.74072462e-01  1.47732228e-01  4.49086070e-01\n",
      " -1.63332358e-01 -4.72899005e-02 -2.98231602e-01 -1.16966099e-01]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_features = 300\n",
    "min_word_count = 40\n",
    "num_workers = 4\n",
    "context = 20\n",
    "downsampling = 1e-3\n",
    "model = word2vec.Word2Vec(sentences_train, workers=num_workers, vector_size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
    "print(sentences_train[:1])\n",
    "print(model.wv[1].shape)\n",
    "print(model.wv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19878cb6-5b6b-460d-a3a2-b76bf871ad70",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19878cb6-5b6b-460d-a3a2-b76bf871ad70",
    "outputId": "ef52c359-d053-460b-bfc6-174a6181af12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Числовые вектора предложений полученные из усреднения его векторов слов:\n",
      "[[ 0.01122577  0.1648979  -0.02985618 ... -0.0644412   0.05634512\n",
      "  -0.10626563]\n",
      " [ 0.01660705  0.15107937 -0.02373466 ... -0.06420577  0.06979375\n",
      "  -0.10469719]\n",
      " [ 0.03489444  0.17293017 -0.0200489  ... -0.05951793  0.07664739\n",
      "  -0.1255422 ]\n",
      " ...\n",
      " [ 0.04794977  0.1994577   0.00728247 ... -0.0754095   0.18881232\n",
      "  -0.09791721]\n",
      " [ 0.03975372  0.16338009 -0.02574402 ... -0.05212484  0.04833128\n",
      "  -0.13754559]\n",
      " [ 0.0510293   0.20172569  0.01441811 ... -0.08039115  0.21878174\n",
      "  -0.08956188]]\n"
     ]
    }
   ],
   "source": [
    "# получение векторного представления\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    featureVec = np.zeros((num_features,), dtype=\"float32\")\n",
    "    nwords = 0\n",
    "\n",
    "    index2word_set = set(model.wv.index_to_key)\n",
    "\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1\n",
    "            featureVec = np.add(featureVec, model.wv[word])\n",
    "\n",
    "    if nwords == 0:\n",
    "        nwords = 1\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec\n",
    "\n",
    "# получение среднего векторного простнраства для предложения\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    reviewFeatureVecs = np.zeros((len(reviews), num_features), dtype=\"float32\")\n",
    "    counter = 0\n",
    "    for review in reviews:\n",
    "        reviewFeatureVecs[counter] = makeFeatureVec(review, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return reviewFeatureVecs\n",
    "\n",
    "f_matrix_train = getAvgFeatureVecs(sentences_train, model, num_features)\n",
    "f_matrix_test = getAvgFeatureVecs(sentences_test, model, num_features)\n",
    "print(\"Числовые вектора предложений полученные из усреднения его векторов слов:\")\n",
    "print(f_matrix_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e959839-f5b5-4df6-aaa3-cb9f45b77ee4",
   "metadata": {
    "id": "8e959839-f5b5-4df6-aaa3-cb9f45b77ee4"
   },
   "source": [
    "## Обучение  MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "459acb4f-d2b4-4b83-a3eb-7d3fe381ca61",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "459acb4f-d2b4-4b83-a3eb-7d3fe381ca61",
    "outputId": "cce17438-2732-488d-a669-e70a8dc20580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLPClassifier(hidden_layer_sizes=(100, 50, 20), random_state=1)]\n"
     ]
    }
   ],
   "source": [
    "model = []\n",
    "#adam солвер это стохастически градиентный оптимизатор\n",
    "m = MLPClassifier(solver='adam', hidden_layer_sizes=(100,50,20), random_state=1)\n",
    "model.append(m)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55185a4e-8a2b-4729-92df-d8e317225e6e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55185a4e-8a2b-4729-92df-d8e317225e6e",
    "outputId": "f39a0c28-c260-4167-f62b-19d7e6baeaff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "total_rows = f_matrix_train.shape[0]\n",
    "duration = 0\n",
    "start_train = time()\n",
    "pos = 0\n",
    "classes = [0.0, 1.0]\n",
    "while duration < 10 and pos < total_rows:\n",
    "    if pos+batch_size > total_rows:\n",
    "        batch_size = total_rows-pos\n",
    "    X_p = f_matrix_train[pos:pos+batch_size]\n",
    "    y_p = y_train.values[pos:pos+batch_size]\n",
    "    model[0].partial_fit(X_p, y_p, classes)\n",
    "    pos = pos + batch_size\n",
    "    duration = time() - start_train\n",
    "    if pos == total_rows:\n",
    "        pos = 0\n",
    "        batch_size = 10000\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8b92fbe-a820-4bfc-9c77-10cbd0e480f7",
   "metadata": {
    "id": "e8b92fbe-a820-4bfc-9c77-10cbd0e480f7"
   },
   "outputs": [],
   "source": [
    "## Сохранение результатов и расчет ошибки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd06d6db-e108-4fb6-92e8-fb9166d6432f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd06d6db-e108-4fb6-92e8-fb9166d6432f",
    "outputId": "e4682906-f1b8-45e4-887a-d0ce46d68ff1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count test values 4324\n",
      "sum_errors 814.0\n",
      "accuracy 81.17483811285847\n"
     ]
    }
   ],
   "source": [
    "y_test_values=y_test.values\n",
    "predicted_results = model[0].predict_proba(f_matrix_test)\n",
    "predicted_results = np.where(predicted_results[:,0]>predicted_results[:,1], 0.0,1.0)\n",
    "\n",
    "sum_errors =sum(y_test_values - predicted_results)\n",
    "accuracy = (len(y_test_values) - sum_errors) / len(y_test_values) *100\n",
    "print('count test values', len(y_test_values))\n",
    "print('sum_errors', sum_errors)\n",
    "print('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62cb7b25-995e-4b15-a998-9710afb0d3ff",
   "metadata": {
    "id": "62cb7b25-995e-4b15-a998-9710afb0d3ff"
   },
   "outputs": [],
   "source": [
    "saved_result = pd.DataFrame({'text':test.values,\n",
    " 'expected':  y_test_values,\n",
    " 'predicted': predicted_results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8aa3432d-e4cb-4d82-9541-70ff693f9489",
   "metadata": {
    "id": "8aa3432d-e4cb-4d82-9541-70ff693f9489"
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'result.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m saved_result\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\Lib\\site-packages\\pandas\\core\\generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3900\u001b[0m )\n\u001b[1;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3903\u001b[0m     path_or_buf,\n\u001b[0;32m   3904\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3905\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3906\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3907\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3908\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3909\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3910\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3911\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3912\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3913\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3914\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3915\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3916\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3917\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3918\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3919\u001b[0m )\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1151\u001b[0m )\n\u001b[1;32m-> 1152\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    250\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    251\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    252\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    253\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    254\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    264\u001b[0m     )\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'result.csv'"
     ]
    }
   ],
   "source": [
    "saved_result.to_csv('result.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877435ef-e795-4995-91ff-bf3dcc61c2f1",
   "metadata": {
    "id": "877435ef-e795-4995-91ff-bf3dcc61c2f1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f70a46-29ee-46db-870c-229b2509eadc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
